from fastapi import FastAPI, UploadFile, File
from pydantic import BaseModel
import pandas as pd

from autogen import AssistantAgent, UserProxyAgent
from autogen.agentchat import GroupChat, GroupChatManager

# =========================
# Global dataset storage
# =========================
DATASET = None

# =========================
# FastAPI app
# =========================
app = FastAPI(title="AutoGen Data Analyzer Backend")

# =========================
# Request schema
# =========================
class AnalyzeRequest(BaseModel):
    query: str

# =========================
# Ollama LLM configuration
# =========================
llm_config = {
    "config_list": [
        {
            "model": "llama3",
            "api_key": "ollama",  # ignored by Ollama
            "base_url": "http://localhost:11434/v1",
        }
    ],
    "temperature": 0.2,
}

# =========================
# AutoGen Agents
# =========================
analyzer_agent = AssistantAgent(
    name="analyzer",
    system_message=(
        "You are a professional data analyst AI. "
        "You are given a dataset preview and structure. "
        "Your job is to analyze patterns, trends, anomalies, "
        "and recommend metrics and visualizations grounded in real data."
    ),
    llm_config=llm_config,
)

user_agent = UserProxyAgent(
    name="user",
    human_input_mode="NEVER",
    code_execution_config={"use_docker": False},
)

group_chat = GroupChat(
    agents=[user_agent, analyzer_agent],
    messages=[],
    max_round=2,
    speaker_selection_method="round_robin",
    allow_repeat_speaker=False,
)

group_chat_manager = GroupChatManager(
    groupchat=group_chat,
    llm_config=llm_config,
)

# =========================
# CSV upload endpoint
# =========================
@app.post("/upload_csv")
async def upload_csv(file: UploadFile = File(...)):
    global DATASET

    df = pd.read_csv(file.file)
    DATASET = df

    return {
        "filename": file.filename,
        "columns": list(df.columns),
        "rows": len(df),
        "preview": df.head().to_dict()
    }

# =========================
# Analyze endpoint
# =========================
@app.post("/analyze")
def analyze_data(request: AnalyzeRequest):
    global DATASET

    if DATASET is None:
        return {"error": "No CSV uploaded yet."}

    # Reset conversation memory
    group_chat.messages.clear()

    # Build safe dataset summary
    summary = f"""
Columns: {list(DATASET.columns)}
Rows: {len(DATASET)}

Sample:
{DATASET.head(10).to_string()}
"""

    full_prompt = f"""
Dataset info:
{summary}

User question:
{request.query}
"""

    # Run AutoGen chat
    user_agent.initiate_chat(
        group_chat_manager,
        message=full_prompt,
    )

    # Extract analyzer response
    final_response = None
    for msg in reversed(group_chat.messages):
        if msg.get("name") == "analyzer":
            final_response = msg.get("content")
            break

    if not final_response:
        final_response = "No response generated by the model."

    return {"analysis_plan": final_response}
